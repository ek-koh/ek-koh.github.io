---
title:  "머신러닝 앙상블 학습(Ensemble Learning) - 부스팅(Boosting) (1)"
excerpt: "앙상블 학습 방식 중 하나인 부스팅(Boosting) 알고리즘의 개념과 GBM에 대해 정리한 글입니다."
toc: true
toc_sticky: true

categories:
  - Data Analysis
tags:
  - [Data Analysis, Machine Learning, Classification, Ensemble, Boosting, GBM, Scikit learn]
last_modified_at: 2020-10-06 21:50:58
---

부스팅 알고리즘은 여러 개의 약한 학습기를 순차적으로 학습하고 예측하면서 잘못 예측한 데이터에 가중치를 부여하며 오류를 개선해 나가는 방식이다. 대표적으로 AdaBoost(Adaptive Boosting), GBM(Gradient Boosting Machine), XGBoost(eXtra Gradient Boost), LightGBM(Light Gradient Boost)이 있다. 이 글에서는 GBM에 대해 다루고자 한다.  

## 1. GBM (Gradient Boosting Machine)  

GBM은 경사 하강법(Gradient Descent)를 이용해 가중치 업데이트를 수행하는 기법이다. GBM이 일반적으로 랜덤포레스트보다 성능이 뛰어나기는 하지만, 수행 시간이 오래 걸린다는 단점이 있다.    

```
경사하강법이란?

h(x) = y - F(x)라고 할 때, h(x)를 최소화하는 방향으로 가중치 값을 업데이트하는 방법

- h(x) : 오류식
- y : 분류의 실제 결과값
- F(x) : 피처 기반 예측함수(예측값)
```

## 2. 사이킷런에서 구현하기  

사이킷런은 GBM 기반의 분류를 위해 GradientBoostingClassifier 클래스를 제공한다.  

```py
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

cancer = load_breast_cancer()

X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=0)

gb_clf = GradientBoostingClassifier(random_state=0)
gb_clf.fit(X_train, y_train)
pred = gb_clf.predict(X_test)
accuracy = accuracy_score(y_test, pred)
print('GBM 정확도: {0:.4f}'.format(accuracy)) # 0.9649
```  



