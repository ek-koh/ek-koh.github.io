---
title:  "분류 평가방법 (3) - F1 스코어, ROC AUC"
excerpt: "정밀도와 재현율을 결합한 지표인 F1 스코어에 대해, 그리고 ROC 곡선과 이를 기반으로 한 AUC 스코어에 대해 정리한 글입니다."
toc: true
toc_sticky: true

categories:
  - Data Analysis
tags:
  - [Data Analysis, Machine Learning, Scikit learn, Metrics, Classification, Evaluation, F1 Score, ROC AUC]
last_modified_at: 2020-09-20 22:49:19
---

["분류 평가방법 (1) - 정확도(Accuracy), 정밀도(Precision), 재현율(Recall)"](https://ek-koh.github.io/data%20analysis/evaluation/) 글에서 정밀도와 재현율은 경우에 따라 상대적 중요성이 달라진다고 하였다. 이에 따라 두 수치 중 하나의 수치를 높게 조정하고 싶을 때는 이전 글 ["분류 평가방법 (2) - 정밀도(Precision), 재현율(Recall)의 트레이드오프"](https://ek-koh.github.io/data%20analysis/pr-tradeoff/)에서 언급한 것과 같은 방식을 사용할 수 있었다.
하지만, 첫 번째 글에서 언급했듯 가장 좋은 것은 두 수치 모두 높은 상태이며 두 수치간의 차이가 심해서는 안된다. 이를 반영한 지표가 바로 F1 스코어이다.  

## 1. F1 스코어  

F1 스코어는 정밀도와 재현율을 결합한 분류 평가 지표이다.  

F1 스코어는 정밀도와 재현율이 한쪽으로 치우치지 않을 때 상대적으로 높은 수치를 나타내게 되며, 두 수치간 차이가 심해지면 F1 스코어가 떨어진다.  

F1 스코어를 구하는 공식은 다음과 같다.  

![image](https://user-images.githubusercontent.com/58713684/93713291-cc080d00-fb95-11ea-928f-df52ceef1c68.png)  

사이킷런에서는 `f1_score()`라는 API를 사용해 F1 스코어를 구할 수 있다.  

```py
from sklearn.metrics import f1_score

# 테스트 피처 데이터셋: X_test
pred  = lr_clf.predict(X_test)
f1_score(y_test , pred)
```  

## 2. ROC 곡선과 AUC 스코어  

ROC 곡선(Receiver Operation Characteristic Curve)과 이를 기반으로 한 AUC(Area Under Curve)는 이진분류 모델의 예측 성능에서 중요하게 사용되는 지표이다.  

먼저 ROC 곡선은 FPR(False Positive Rate)의 변화에 따른 TPR(True Positive Rate)의 변화를 나타내는 곡선이다.  

- FPR(False Positive Rate)
  - 실제 Negative(음성, 0)를 잘못 예측한 비율
  - `FP / (FP + TN)`
- TPR(True Positive Rate)
  - 실제 Positive(양성, 1)가 정확히 예측되어야 하는 수준
  - 재현율(Recall), 민감도(Sensitivity)라고도 불린다.
  - `TP / (FN + TP)`
- TNR(True Negative Rate)
  - 실제 Negatvie(음성, 0)가 정확히 예측되어야 하는 수준
  - 특이성(Specificity)이라고도 불린다.
  - `TN / (FP + TN)`
  - FPR = 1 - TNR  

사이킷런에서는 `roc_curve()` API를 통해 ROC 곡선을 그려볼 수 있다.  

```py
from sklearn.metrics import roc_curve

def roc_curve_plot(y_test , pred_proba_c1):
    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)

    # ROC Curve
    plt.plot(fprs , tprs, label='ROC')
    # 가운데 대각선
    plt.plot([0, 1], [0, 1], 'k--', label='Random')
    
    # 그래프 설정: x scale, x/y lim, label, legend
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start, end, 0.1),2))
    plt.xlim(0,1)
    plt.ylim(0,1)
    plt.xlabel('FPR')
    plt.ylabel('TPR')
    plt.legend()
    plt.show()
    
# Estimator: lr_clf
# 테스트 피처 데이터셋: X_test
# 테스트 레이블 데이터셋: y_test
roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )
```  

![image](https://user-images.githubusercontent.com/58713684/93713941-34f18400-fb9a-11ea-9629-cb097de4a588.png)  


임계값이 1에서 작아질수록 FPR은 커지며, FPR이 조금씩 커질 때 TPR은 가파르게 커진다. 가운데 대각선은 ROC 곡선의 최저 값, 즉 Random 이진 분류의 ROC 곡선을 나타낸다. ROC 곡선을 그렸을 때 **가운데 대각선에 가깝다면 성능이 떨어진 것이고, 멀어질수록 성능이 좋은 것**이라고 보면 된다.  

AUC(Area Under Curve)는 이러한 ROC 곡선 밑의 면적을 구한 것이며, **1에 가까울수록 좋은 수치로 판단**한다. ROC 곡선이 가운데 대각선과 일치한다면 AUC 값은 0.5가 된다.  

사이킷런에서는 `roc_auc_score()`로 AUC 스코어를 구할 수 있다.  

```py
from sklearn.metrics import roc_auc_score

# Estimator: lr_clf
# 테스트 피처 데이터셋: X_test
# 테스트 레이블 데이터셋: y_test
pred_proba = lr_clf.predict_proba(X_test)[:, 1]
roc_auc_score(y_test, pred_proba)
```  





